{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# First view of text file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018\n"
     ]
    }
   ],
   "source": [
    "folder_path = '/Users/thibaud/Documents/data/DVF/'\n",
    "file_name = 'valeursfoncieres-2018.txt'\n",
    "file_path = folder_path + file_name\n",
    "year_file = int(file_name.split('.')[0].split('-')[-1])\n",
    "print(year_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Code service CH', 'Reference document', '1 Articles CGI', '2 Articles CGI', '3 Articles CGI', '4 Articles CGI', '5 Articles CGI', 'No disposition', 'Date mutation', 'Nature mutation', 'Valeur fonciere', 'No voie', 'B/T/Q', 'Type de voie', 'Code voie', 'Voie', 'Code postal', 'Commune', 'Code departement', 'Code commune', 'Prefixe de section', 'Section', 'No plan', 'No Volume', '1er lot', 'Surface Carrez du 1er lot', '2eme lot', 'Surface Carrez du 2eme lot', '3eme lot', 'Surface Carrez du 3eme lot', '4eme lot', 'Surface Carrez du 4eme lot', '5eme lot', 'Surface Carrez du 5eme lot', 'Nombre de lots', 'Code type local', 'Type local', 'Identifiant local', 'Surface reelle bati', 'Nombre pieces principales', 'Nature culture', 'Nature culture speciale', 'Surface terrain\\n']\n",
      "['', '', '', '', '', '', '', '000001', '03/01/2018', 'Vente', '109000,00', '13', '', 'RUE', '1660', 'GEN LOGEROT', '1000', 'BOURG-EN-BRESSE', '01', '53', '', 'AN', '73', '', '13', '', '', '', '', '', '', '', '', '', '1', '3', 'DÃ©pendance', '', '0', '0', '', '', '\\n']\n"
     ]
    }
   ],
   "source": [
    "with open(file_path) as file:\n",
    "    first_line = file.readline()\n",
    "    first_line = first_line.split('|')\n",
    "    \n",
    "    second_line = file.readline()\n",
    "    second_line = second_line.split('|')\n",
    "\n",
    "print(first_line)\n",
    "print(second_line)\n",
    "\n",
    "df = pd.DataFrame(columns=first_line, index=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500000\n",
      "1000000\n",
      "1500000\n",
      "2000000\n"
     ]
    }
   ],
   "source": [
    "values = list()\n",
    "with open(file_path, 'r') as f:\n",
    "    c=0\n",
    "    for line in f:\n",
    "        if c==0:\n",
    "            rep = line\n",
    "        elif c % 500000==0:\n",
    "            print(c)\n",
    "        values.append(line)\n",
    "        c+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**************************************************\n",
      "> 0\n",
      "**************************************************\n",
      "2339003\n",
      "|||||||000001|28/12/2018|Vente|405000,00|13||RUE|0797|BEAUTREILLIS|75004|PARIS 04|75|104||AQ|16||16|33,87|27||||||||2|2|Appartement||34|1|||\n",
      "\n",
      "Selecting\n",
      "Splitting\n",
      "DataFraming\n",
      "Processing\n",
      "Saving\n",
      "dept_01.csv already existing. Concatenating with previous one.\n",
      "dept_02.csv already existing. Concatenating with previous one.\n",
      "dept_03.csv already existing. Concatenating with previous one.\n",
      "dept_04.csv already existing. Concatenating with previous one.\n",
      "dept_05.csv already existing. Concatenating with previous one.\n",
      "dept_06.csv already existing. Concatenating with previous one.\n",
      "dept_07.csv already existing. Concatenating with previous one.\n",
      "dept_08.csv already existing. Concatenating with previous one.\n",
      "dept_09.csv already existing. Concatenating with previous one.\n",
      "dept_10.csv already existing. Concatenating with previous one.\n",
      "dept_11.csv already existing. Concatenating with previous one.\n",
      "dept_12.csv already existing. Concatenating with previous one.\n",
      "dept_13.csv already existing. Concatenating with previous one.\n",
      "dept_14.csv already existing. Concatenating with previous one.\n",
      "dept_15.csv already existing. Concatenating with previous one.\n",
      "dept_16.csv already existing. Concatenating with previous one.\n",
      "dept_17.csv already existing. Concatenating with previous one.\n",
      "dept_18.csv already existing. Concatenating with previous one.\n",
      "dept_19.csv already existing. Concatenating with previous one.\n",
      "dept_21.csv already existing. Concatenating with previous one.\n",
      "dept_22.csv already existing. Concatenating with previous one.\n",
      "dept_23.csv already existing. Concatenating with previous one.\n",
      "dept_24.csv already existing. Concatenating with previous one.\n",
      "dept_25.csv already existing. Concatenating with previous one.\n",
      "dept_26.csv already existing. Concatenating with previous one.\n",
      "dept_27.csv already existing. Concatenating with previous one.\n",
      "dept_28.csv already existing. Concatenating with previous one.\n",
      "dept_29.csv already existing. Concatenating with previous one.\n",
      "dept_2A.csv already existing. Concatenating with previous one.\n",
      "dept_2B.csv already existing. Concatenating with previous one.\n",
      "dept_30.csv already existing. Concatenating with previous one.\n",
      "dept_31.csv already existing. Concatenating with previous one.\n",
      "['01', '02', '03', '04', '05', '06', '07', '08', '09', '10', '11', '12', '13', '14', '15', '16', '17', '18', '19', '21', '22', '23', '24', '25', '26', '27', '28', '29', '2A', '2B', '30', '31']\n",
      "**************************************************\n",
      "> 600000\n",
      "**************************************************\n",
      "2339003\n",
      "|||||||000001|28/12/2018|Vente|405000,00|13||RUE|0797|BEAUTREILLIS|75004|PARIS 04|75|104||AQ|16||16|33,87|27||||||||2|2|Appartement||34|1|||\n",
      "\n",
      "Selecting\n",
      "Splitting\n",
      "DataFraming\n",
      "Processing\n",
      "Saving\n",
      "dept_31.csv already existing. Concatenating with previous one.\n",
      "dept_32.csv already existing. Concatenating with previous one.\n",
      "dept_33.csv already existing. Concatenating with previous one.\n",
      "dept_34.csv already existing. Concatenating with previous one.\n",
      "dept_35.csv already existing. Concatenating with previous one.\n",
      "dept_36.csv already existing. Concatenating with previous one.\n",
      "dept_37.csv already existing. Concatenating with previous one.\n",
      "dept_38.csv already existing. Concatenating with previous one.\n",
      "dept_39.csv already existing. Concatenating with previous one.\n",
      "dept_40.csv already existing. Concatenating with previous one.\n",
      "dept_41.csv already existing. Concatenating with previous one.\n",
      "dept_42.csv already existing. Concatenating with previous one.\n",
      "dept_43.csv already existing. Concatenating with previous one.\n",
      "dept_44.csv already existing. Concatenating with previous one.\n",
      "dept_45.csv already existing. Concatenating with previous one.\n",
      "dept_46.csv already existing. Concatenating with previous one.\n",
      "dept_47.csv already existing. Concatenating with previous one.\n",
      "dept_48.csv already existing. Concatenating with previous one.\n",
      "dept_49.csv already existing. Concatenating with previous one.\n",
      "dept_50.csv already existing. Concatenating with previous one.\n",
      "['01', '02', '03', '04', '05', '06', '07', '08', '09', '10', '11', '12', '13', '14', '15', '16', '17', '18', '19', '21', '22', '23', '24', '25', '26', '27', '28', '29', '2A', '2B', '30', '31', '31', '32', '33', '34', '35', '36', '37', '38', '39', '40', '41', '42', '43', '44', '45', '46', '47', '48', '49', '50']\n",
      "**************************************************\n",
      "> 1200000\n",
      "**************************************************\n",
      "2339003\n",
      "|||||||000001|28/12/2018|Vente|405000,00|13||RUE|0797|BEAUTREILLIS|75004|PARIS 04|75|104||AQ|16||16|33,87|27||||||||2|2|Appartement||34|1|||\n",
      "\n",
      "Selecting\n",
      "Splitting\n",
      "DataFraming\n",
      "Processing\n",
      "Saving\n",
      "dept_50.csv already existing. Concatenating with previous one.\n",
      "dept_51.csv already existing. Concatenating with previous one.\n",
      "dept_52.csv already existing. Concatenating with previous one.\n",
      "dept_53.csv already existing. Concatenating with previous one.\n",
      "dept_54.csv already existing. Concatenating with previous one.\n",
      "dept_55.csv already existing. Concatenating with previous one.\n",
      "dept_56.csv already existing. Concatenating with previous one.\n",
      "dept_58.csv already existing. Concatenating with previous one.\n",
      "dept_59.csv already existing. Concatenating with previous one.\n",
      "dept_60.csv already existing. Concatenating with previous one.\n",
      "dept_61.csv already existing. Concatenating with previous one.\n",
      "dept_62.csv already existing. Concatenating with previous one.\n",
      "dept_63.csv already existing. Concatenating with previous one.\n",
      "dept_64.csv already existing. Concatenating with previous one.\n",
      "dept_65.csv already existing. Concatenating with previous one.\n",
      "dept_66.csv already existing. Concatenating with previous one.\n",
      "dept_69.csv already existing. Concatenating with previous one.\n",
      "dept_70.csv already existing. Concatenating with previous one.\n",
      "dept_71.csv already existing. Concatenating with previous one.\n",
      "dept_72.csv already existing. Concatenating with previous one.\n",
      "dept_73.csv already existing. Concatenating with previous one.\n",
      "dept_74.csv already existing. Concatenating with previous one.\n",
      "dept_76.csv already existing. Concatenating with previous one.\n",
      "dept_77.csv already existing. Concatenating with previous one.\n",
      "dept_78.csv already existing. Concatenating with previous one.\n",
      "['01', '02', '03', '04', '05', '06', '07', '08', '09', '10', '11', '12', '13', '14', '15', '16', '17', '18', '19', '21', '22', '23', '24', '25', '26', '27', '28', '29', '2A', '2B', '30', '31', '31', '32', '33', '34', '35', '36', '37', '38', '39', '40', '41', '42', '43', '44', '45', '46', '47', '48', '49', '50', '50', '51', '52', '53', '54', '55', '56', '58', '59', '60', '61', '62', '63', '64', '65', '66', '69', '70', '71', '72', '73', '74', '76', '77', '78']\n",
      "**************************************************\n",
      "> 1800000\n",
      "**************************************************\n",
      "2339003\n",
      "|||||||000001|28/12/2018|Vente|405000,00|13||RUE|0797|BEAUTREILLIS|75004|PARIS 04|75|104||AQ|16||16|33,87|27||||||||2|2|Appartement||34|1|||\n",
      "\n",
      "Selecting\n",
      "Splitting\n",
      "DataFraming\n",
      "Processing\n",
      "Saving\n",
      "dept_78.csv already existing. Concatenating with previous one.\n",
      "dept_79.csv already existing. Concatenating with previous one.\n",
      "dept_80.csv already existing. Concatenating with previous one.\n",
      "dept_81.csv already existing. Concatenating with previous one.\n",
      "dept_82.csv already existing. Concatenating with previous one.\n",
      "dept_83.csv already existing. Concatenating with previous one.\n",
      "dept_84.csv already existing. Concatenating with previous one.\n",
      "dept_85.csv already existing. Concatenating with previous one.\n",
      "dept_86.csv already existing. Concatenating with previous one.\n",
      "dept_87.csv already existing. Concatenating with previous one.\n",
      "dept_88.csv already existing. Concatenating with previous one.\n",
      "dept_89.csv already existing. Concatenating with previous one.\n",
      "dept_90.csv already existing. Concatenating with previous one.\n",
      "dept_91.csv already existing. Concatenating with previous one.\n",
      "dept_92.csv already existing. Concatenating with previous one.\n",
      "dept_93.csv already existing. Concatenating with previous one.\n",
      "dept_94.csv already existing. Concatenating with previous one.\n",
      "dept_95.csv already existing. Concatenating with previous one.\n",
      "dept_971.csv already existing. Concatenating with previous one.\n",
      "dept_972.csv already existing. Concatenating with previous one.\n",
      "dept_973.csv already existing. Concatenating with previous one.\n",
      "dept_974.csv already existing. Concatenating with previous one.\n",
      "dept_75.csv already existing. Concatenating with previous one.\n",
      "['01', '02', '03', '04', '05', '06', '07', '08', '09', '10', '11', '12', '13', '14', '15', '16', '17', '18', '19', '21', '22', '23', '24', '25', '26', '27', '28', '29', '2A', '2B', '30', '31', '31', '32', '33', '34', '35', '36', '37', '38', '39', '40', '41', '42', '43', '44', '45', '46', '47', '48', '49', '50', '50', '51', '52', '53', '54', '55', '56', '58', '59', '60', '61', '62', '63', '64', '65', '66', '69', '70', '71', '72', '73', '74', '76', '77', '78', '78', '79', '80', '81', '82', '83', '84', '85', '86', '87', '88', '89', '90', '91', '92', '93', '94', '95', '971', '972', '973', '974', '75']\n",
      "> Finished.\n"
     ]
    }
   ],
   "source": [
    "col = rep.split('|')\n",
    "saved_dept = []\n",
    "for i in [0, 600000, 1200000, 1800000]:\n",
    "    print('*'*50)\n",
    "    print('> ' + str(i))\n",
    "    print('*'*50)\n",
    "    \n",
    "    print(len(values))\n",
    "    print(line)\n",
    "\n",
    "    print('Selecting')\n",
    "    v_small = values[i:i+600000]\n",
    "\n",
    "    print('Splitting')\n",
    "    v_small = [i.split('|') for i in v_small]\n",
    "    # np_values = np.array(v_small)\n",
    "\n",
    "    print('DataFraming')\n",
    "    df = pd.DataFrame(v_small[1:],columns=col)\n",
    "    \n",
    "    print('Processing')\n",
    "    df = df.replace('', np.NaN).rename(columns={'Surface terrain\\n':'Surface terrain'})\n",
    "    df['Surface terrain'] = df['Surface terrain'].apply(lambda x : x.replace('\\n', ''))\n",
    "    \n",
    "    print('Saving')\n",
    "    path = folder_path + 'data_per_dept/raw_{}/'.format(year_file)\n",
    "    for dept in df['Code departement'].unique():\n",
    "        df_dept = df[df['Code departement']==dept]\n",
    "        dept_file_name = 'dept_{}.csv'.format(dept)\n",
    "        if dept_file_name in os.listdir(path):\n",
    "            print('{} already existing. Concatenating with previous one.'.format(dept_file_name))\n",
    "            previous_dept = pd.read_csv('{}{}'.format(path, dept_file_name), low_memory=False)\n",
    "            df_dept = pd.concat([previous_dept, df_dept]).head()\n",
    "        df_dept.to_csv('{}{}'.format(path, dept_file_name), index=False)\n",
    "        saved_dept.append(dept)\n",
    "    del(df)\n",
    "    print(saved_dept)\n",
    "print('> Finished.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Time to explore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
